```{r}
data = read.csv('ames_housing.csv')
data$Neighborhood = as.factor(data$Neighborhood)

set.seed(42)

#Randomly sample 50% of the obsercation for training
train = sample(1:nrow(data), round(.5*nrow(data)))

test = -train

data_train = data[train,]
data_test = data[test,]

test_model_aic = lm(SalePrice ~ LotArea + Neighborhood + OverallQual + OverallCond + YearBuilt + YearRemodAdd + BsmtFinSf1 + TotalBsmtSf + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + GarageCars + WoodDeckSf + OpenPorchSf + ScreenPorch, data = data_test)

noninfluential_ids = which(
    cooks.distance(test_model_aic) <= 4 / length(cooks.distance(test_model_aic)))

model_fix_aic = lm(SalePrice ~ LotArea + Neighborhood + OverallQual + OverallCond + YearBuilt + YearRemodAdd + BsmtFinSf1 + TotalBsmtSf + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + GarageCars + WoodDeckSf + OpenPorchSf + ScreenPorch, data = data_test, subset=noninfluential_ids)
```

```{r}
summary(model_fix_aic)
```

The final model is only valid under few assumptions. They are:

1.  **Linearity**

2.  **Independence**

3.  **Normality**

4.  **Equal Variance**

Let's check how well the final model follow these assumptions.

### Linearity

This can be visually inspected by looking at the fitted values vs residuals model. Let's first get the plot of residuals vs fitted values.

```{r, message = FALSE}
library(olsrr)

ols_plot_resid_fit(model_fix_aic)
```

The residuals seems to be evenly spread and sums up to 0. Therefore, we can conclude that the linearity assumption is not violated.

### Constant Variance

The constant variance assumption can be checked visually by looking at the spread of the residuals vs fitted values plot above. As the spread seems to be even, we can conclude that the constant variance assumption is not violated. To further confirm this, we can perform the Breush-Pagan test. Let's test the hypothesis at $\alpha = 0.05$ significance level.

```{r, message = FALSE}
library(lmtest)
bptest(model_fix_aic)
```

The test statistic is 22.916 and the p-value is 0.4657. Therefore, at $\alpha=0.05$ significant level, we fail to reject the null hypothesis. Thus, we conclude that the errors have a constant variance.

### Normality

The normality assumption can be checked graphically by looking at the Q-Q plots.

```{r}
ols_plot_resid_qq(model_fix_aic)
```

There seems to be a little deviation from the 45 degree line but overall it looks like the normality assumption is not violated. To further confirm this, we can use the Shapiro-Wilk test. Let's test the hypothesis at $\alpha = 0.05$ significance level.

```{r}
shapiro.test(resid(model_fix_aic))
```

The test statistic value is 0.9953 with the p-value is at 0.3544. Therefore, we fail to reject the null at $\alpha = 0.05$ significance level. Hence, we conclude that the errors follow a normal distribution.

## Section 3

Overall we conclude that the final model follow the LINE assumptions. Now we will look at the linear significance of the model we chose.

```{r}
summary(model_fix_aic)
```

The null and alternative hypotheses are:

$$
H_0: \beta_{\text{LotArea}}= \beta_{\text{NeighborhoodEdwards}}= ... =  \beta_{\text{ScreenPorch}} = 0 \qquad \text{vs.} \qquad H_1: \text{ At least one of the } \beta_j \text{ from the null is not 0}.
$$

The value of the F-test statistic is 194.9. The p-value of the test is less than $2.2 \times 10^{-16}$, so we will reject the null hypothesis at the $\alpha = 0.05$ significance level and conclude that at least one of the predictors has a significant linear relationship with the `Sale Price`.

Next, let's look at the model fit.

```{r}
summary(model_fix_aic)$r.squared
```

We see that the final model is able to explain 93.07% of the observed variability in sales price of a home by the linear relationship between the predictors of the final model given above. This is important because having a high inalienability of the sales price of houses can lead to better valuation in the context of the business case.

Now we will test the significance of specific predictors from our hypothesis, which includes `LotArea`, `Neighborhood`, `OverallQual` and `OverallCond`. Since `Neighboorhood` is categorical we will perform a nested model comparison with an F-test.

```{r}
restricted_neighborhood = lm(SalePrice ~ LotArea + OverallQual + OverallCond + YearBuilt + YearRemodAdd + BsmtFinSf1 + TotalBsmtSf + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + GarageCars + WoodDeckSf + OpenPorchSf + ScreenPorch, data = data_test, subset=noninfluential_ids)

anova(restricted_neighborhood, model_fix_aic)
```

The value of the F-test statistic is 15.842. The p-value of the test is $6.948 \times 10^{-12}$, so we will reject the null hypothesis at the $\alpha = 0.05$ significance level. As such, we reject the null hypothesis and conclude that there is a significant linear relationship between `Neighborhood` and `Sale Price`, when the other predictors are in the model.

```{r}
summary(model_fix_aic)$coefficients
```

Here we can see that the Edwards and NAmes neighborhoods are significant at the $\alpha = 0.05$ significance level, but the intercept for Old Town and Sawyer neighborhoods are not significantly different from the intercept of CollgCr at the $\alpha = 0.05$ significance level.

Now we will check to see if our three other predictors are significant. In the following table it lists the other variables as well as their corresponding t-values and p-values, where significant p-values are in bold.

```{r, echo=FALSE}
options(knitr.kable.NA = '')
data.frame("Predictor" = c("Lot Area", "Overall Quality", "Overall Condition"),
           "t-value" = c("6.590","10.991", "9.971"),
           "p-value" = c("**1.72e-10**","**< 2e-16**", "**< 2e-16**")) |>
  knitr::kable()
```

As we can see from the table all three of these variables have p-values less than 0.05 which means that all three have a linearly significant relationship with `Sale Price` when the other predictors are in the model.

Finally we will look at the confidence intervals for the numerical predictors that we have been looking at in order to find the degree of certainty for this model.


```{r}
confint(model_fix_aic, parm = 'LotArea', level = 0.95)

confint(model_fix_aic, parm = 'OverallQual', level = 0.95)

confint(model_fix_aic, parm = 'OverallCond', level = 0.95)

```

```{r, echo=FALSE}
options(knitr.kable.NA = '')
data.frame("Predictor" = c("LotArea", "OverallQual", "OverallCond"),
           "CI Interval" = c("(0.8689364, 1.608444)", "(5546.233, 7964.23)", "(3733.951, 5569.39)")) |>
  knitr::kable()
```

Above is the table that shows us the 95\% confidence interval for each predictor. An interesting thing to note that we are 95\% confident that when a houses lot area increases by 1 square foot, and the other predictors remain the same, the average increase in the houses Sale Price is between \$0.87 and \$1.61. This means that with the addition of one square foot it will account for roughly \$1 to \$1.50 of the houses `Sale Price`. While that is not much on the small scale, when a house is larger than another house by a few hundred square feet it will greatly increase the `Sale Price`. It also seems that the overall quality score and overall condition score greatly influence the `Sale Price`, where our 95\% confidence interval shows us that with an increase by one point in each category it will increase the `Sale Price` of the house by \$5,546.23 to \$7,964.23 and \$3,733.95 to \$5,569.39 respectively.

